{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Testing different ways of multiplying matices in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "Python's time module provides various time-related functions. We are going to utilize it in order to calculate how long does it take to perform operations.\n",
    "In this Homework, we will cover:\n",
    "\n",
    "- The CUDA programming model\n",
    "- Accelerating numerical python code with `numba`\n",
    "- Implementing CUDA kernels in python\n",
    "- Thread synchronization\n",
    "- Shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=cuda\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type != \"cuda\":\n",
    "    raise RuntimeError(\"This tutorial requires a GPU!\")\n",
    "\n",
    "print(f\"Using {device=!s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Kernel \"Geometry\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Key idea of CUDA\n",
    "\n",
    "- Write a single-threaded program with the **thread id** as a parameter.\n",
    "- Use thread id to select a subset of data to process.\n",
    "- Launch many threads, so that together they cover the entire range of input data.\n",
    "- Code automatically scales to all available physical processors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "\n",
    "<left>\n",
    "<h3> Shared memory <h3/>\n",
    "- Shared between threads in the same thread block\n",
    "<br/>\n",
    "- Used for collaboration between threads in the same block\n",
    "<br/>\n",
    "- On chip $\\rightarrow$ very fast\n",
    "<br/>\n",
    "- Persisted until end of block\n",
    "<br/>\n",
    "<br/>\n",
    "    \n",
    "</left>\n",
    "\n",
    "<right>\n",
    "    \n",
    "<h3> Global memory <h3/>\n",
    "- Can be accessed by any thread in any thread block\n",
    "    <br/>\n",
    "- Used to copy to/from host\n",
    "    <br/>\n",
    "- Located in DRAM $\\rightarrow$ slow\n",
    "    <br/>\n",
    "- Persisted for the life of the application\n",
    "    <br/>\n",
    "    <br/>\n",
    "\n",
    "</right>\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "https://github.com/Muhammad-Dah/Matrix-Multiplication/blob/main/img/mem_global.png?raw=true",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "plt_results(N_choices, cpu_times, numpy_times, cuda_naive_times, cuda_fast_times, to_scale = 'µs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Heuristics for Kernel sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many blocks?\n",
    "- Should occupy every SM $\\rightarrow$ At least one block per SM\n",
    "- Should have something to run on SM if current block is waiting (e.g. sync) $\\rightarrow$ At least two blocks per SM\n",
    "- Should scale with same code if we upgrade hardware $\\rightarrow$ Many blocks per SM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many threads?\n",
    "- Many threads $\\rightarrow$ hides global memory latency\n",
    "- Too many threads $\\rightarrow$ exhaust registers and shared memory\n",
    "- Should be a multiple of warp size\n",
    "- Typical selection: 64 to 512 per block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing CUDA Kernels with `numba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is `numba`?\n",
    "\n",
    "Numba is a **just-in-time** (JIT) **function compiler**, focused on **numerical python**.\n",
    "It can be used to accelerate python code by generating efficient, **type-specialized** machine code.\n",
    "Numba supports all major OSes and a wide range of hardware (Intel x86/64, NVIDIA CUDA, ARM).\n",
    "It's developed and actively maintained by Anaconda Inc., and considered production ready.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First steps with `numba` on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0             b'TITAN Xp'                              [SUPPORTED]\n",
      "                      compute capability: 6.1\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 7\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "# Show GPUs on the machine\n",
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplication accumulation : D = AxB + C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU implementation\n",
    "#### Pure Python implementation \n",
    "Our implementation will be purely based on Python. We will not use any external libraries. We need three loops here. The first loop is for all rows in first matrix, 2nd one is for all columns in second matrix and 3rd one is for all values within each value in the i row and j column of matrices a and b respectively. We need to multiply each elements of i row and j column together and finally sum the values. The final sum is the value for D[i, j].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cpu_matmul_add(A, B, C, D):\n",
    "    N = A.shape[0]\n",
    "    for i in range(N): \n",
    "        for j in range(N):\n",
    "            D[i, j] = C [i, j]\n",
    "            for k in range(N):\n",
    "                D[i, j] += A[i, k] * B[k, j]\n",
    "                \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU matmul_add:\n",
      "791 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kernel geometry: cover the entire matrix with the grid\n",
    "N = 64\n",
    "\n",
    "# Input data \n",
    "a = np.random.rand(N, N) \n",
    "b = np.random.rand(N, N) \n",
    "c = np.random.rand(N, N) \n",
    "cpu_out = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "\n",
    "print('\\nCPU matmul_add:')\n",
    "%timeit -o -r 1 -n 1 pass;  cpu_matmul_add(a, b, c, cpu_out)\n",
    "\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU naive implementation kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_add_kernel(A, B, C, D):\n",
    "    \n",
    "    # Unique thread id on a 2d-grid\n",
    "    i, j = cuda.grid(2)           # location of current thread (i, j)\n",
    "    imax, jmax = cuda.gridsize(2) # total number of threads (I, J)\n",
    "\n",
    "    # Each thread calculates one output element: out[i,j]\n",
    "    if i < D.shape[0] and j < D.shape[1]:\n",
    "        for k in range(B.shape[0]):\n",
    "            D[i, j] += A[i,k] * B[k,j]\n",
    "        D[i, j] += C[i,j]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### 2D kernel geometry set up and random matrix decleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_dim=(32, 32), grid_dim=(2, 2)\n",
      "total_threads=4096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "blocksize = cuda.get_current_device().WARP_SIZE\n",
    "gridsize = (N + blocksize-1)//blocksize\n",
    "\n",
    "block_dim = (blocksize, blocksize)\n",
    "grid_dim = (gridsize, gridsize)\n",
    "\n",
    "print(f'block_dim={block_dim}, grid_dim={grid_dim}')\n",
    "print(f'total_threads={(blocksize**2) * (gridsize**2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing and comperation of numpy and cpu implementation:\n",
    "##### Let's try our simple kernel and compare it to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.28223  , 15.488041 , 15.125814 , ..., 17.013523 , 16.98449  ,\n",
       "        15.143689 ],\n",
       "       [16.821674 , 17.227692 , 17.309969 , ..., 15.40683  , 16.033924 ,\n",
       "        14.614565 ],\n",
       "       [17.841513 , 18.137138 , 16.837236 , ..., 17.617714 , 19.809275 ,\n",
       "        16.196302 ],\n",
       "       ...,\n",
       "       [17.627274 , 16.708979 , 16.101015 , ..., 16.14629  , 17.794588 ,\n",
       "        15.0994215],\n",
       "       [17.181337 , 17.296556 , 16.811516 , ..., 16.71122  , 18.70209  ,\n",
       "        15.767479 ],\n",
       "       [15.714673 , 15.635249 , 16.658735 , ..., 14.713628 , 16.041458 ,\n",
       "        13.472644 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "expected_out = np.matmul(a, b) + c\n",
    "\n",
    "out = np.zeros((N, N), dtype=np.float32)\n",
    "matmul_add_kernel[grid_dim, block_dim](a, b, c, out)\n",
    "\n",
    "# Make sure result is correct\n",
    "assert(np.allclose(out, expected_out))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU, naive implementation:\n",
      "2.16 ms ± 8.94 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nGPU, naive implementation:')\n",
    "%timeit matmul_add_kernel[grid_dim, block_dim](a, b, c, out); cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's about 2k orders of magnitude faster! Not bad for just adding a decorator function...\n",
    "We used lots of threads and a large grid!\n",
    "But, why is this implementation still inefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Both A and B will be read many times from the **slow** global memory:\n",
    "- A will be read `B.shape[1]` times\n",
    "- B will be read `A.shape[0]` times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can move on to a more efficient version which takes take advantage of **shared memory** to reduce\n",
    "global memory bandwidth.\n",
    "Recall that shared memory is on-chip memory available on each streaming multiprocessor.\n",
    "It is shared only between threads of the same block (even if other blocks are running on the same SM).\n",
    "Shared memory is scarce hardware resource, in many cases limited to 48kB per block. It should be used sparingly, as a way to reduce latency of global memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will implement as follows:\n",
    "\n",
    "- Each thread block is responsible for computing one square sub-matrix `D_sub` of the output `D`, of shape `(blocksize,blocksize)`.\n",
    "- Each thread within the block is responsible for computing one element of `D_sub`.\n",
    "- `D_sub` is the product of two rectangular matrices: `A_sub` of shape `(block_size, A.shape[1])` which has the same row indices as `D_sub`, and `B_sub` of shape `(B.shape[0], blocksize)` which has the same column indices as `Dsub`. Then adding from his own cell from matrix `C` to the result.  \n",
    "- These two rectangular matrices are divided into as many square matrices of shape `(blocksize, blocksize)` as necessary.\n",
    "- `D_sub` is computed as the sum of the products of these square matrices. To compute this product:\n",
    "    - First we load two corresponding square matrices from global memory to shared memory with one thread loading one element of each matrix.\n",
    "    - Then each thread computes one element of the product using the shared memory.\n",
    "    - Each thread accumulates the result of each of these square products into a register and once done writes the result to global memory.\n",
    "    - Then we load square matrices from global memory of `C` matrix to shared memory with one thread loading one element of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def fast_matmul_add_kernel(a, b, c, out):\n",
    "    # Define arrays in the shared memory\n",
    "    # These will hold a square block of A_sub and B_sub\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    a_sub = cuda.shared.array(shape=(blocksize, blocksize), dtype=numba.float32)\n",
    "    b_sub = cuda.shared.array(shape=(blocksize, blocksize), dtype=numba.float32)\n",
    "    c_sub = cuda.shared.array(shape=(blocksize, blocksize), dtype=numba.float32)\n",
    "\n",
    "    # Global id of current thread in a 2D threadblock: defines output location\n",
    "    x, y = cuda.grid(2)\n",
    "    \n",
    "    # Bounds check\n",
    "    if x >= out.shape[0] or y >= out.shape[1]:\n",
    "        return\n",
    "    \n",
    "    # Index of thread within it's own block\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of (blocksize,)-shaped vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # i is the index of the current inner square block\n",
    "        \n",
    "        # Get row and col within A_sub and B_sub and do bounds check\n",
    "        b_sub_row = tx + i * blocksize\n",
    "        a_sub_col = ty + i * blocksize\n",
    "        if not (b_sub_row < b.shape[0] and a_sub_col < a.shape[1]):\n",
    "            continue\n",
    "        \n",
    "        # Preload one element from A_sub and B_sub into shared memory\n",
    "        a_sub[tx, ty] = a[x, a_sub_col]\n",
    "        b_sub[tx, ty] = b[b_sub_row, y]\n",
    "\n",
    "        # Wait for all threads in current block\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Compute inner product between vectors, read from the shared memory\n",
    "        for j in range(blocksize):\n",
    "            tmp += a_sub[tx, j] * b_sub[j, ty]\n",
    "        \n",
    "        cuda.syncthreads()\n",
    "\n",
    "        \n",
    "    # Preload one element from C_sub into shared memory\n",
    "    c_sub[tx, ty] = c[x, y]\n",
    "    # Write to global memory\n",
    "    out[x, y] = tmp + c_sub[tx, ty]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What does the `cuda.syncthreads()` call do?\n",
    "\n",
    "Why do we need the first call? And why do we need to second?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This call allows us to use a synchronization mechanism called a **barrier**, between threads within the **same** threadblock.\n",
    "\n",
    "A barrier blocks each thread until all threads reach it, at which point all threads become unblocked.\n",
    "\n",
    "- The first `syncthreads()` call is needed in order to wait for the entire `a_sub` and `b_sub` matrices to fill, since each thread loads only one element.\n",
    "- The second `syncthreads()` is necessary so that a thread will not advance to the next square sub-block. This will cause it to fetch new data into `a_sub` and `b_sub` while another thread might still need the old data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test our faster matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.28223  , 15.488042 , 15.125815 , ..., 17.013521 , 16.98449  ,\n",
       "        15.143691 ],\n",
       "       [16.821676 , 17.227694 , 17.309969 , ..., 15.406833 , 16.033924 ,\n",
       "        14.614565 ],\n",
       "       [17.841515 , 18.137135 , 16.837234 , ..., 17.617718 , 19.809277 ,\n",
       "        16.1963   ],\n",
       "       ...,\n",
       "       [17.627272 , 16.708984 , 16.101013 , ..., 16.146294 , 17.794588 ,\n",
       "        15.0994215],\n",
       "       [17.181337 , 17.296555 , 16.811516 , ..., 16.711218 , 18.70209  ,\n",
       "        15.767479 ],\n",
       "       [15.714674 , 15.635251 , 16.658735 , ..., 14.713627 , 16.041458 ,\n",
       "        13.472643 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "fast_matmul_add_kernel[grid_dim, block_dim](a, b, c, out)\n",
    "\n",
    "# Make sure result is correct\n",
    "assert(np.allclose(out, expected_out))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU, with shared memory:\n",
      "2.1 ms ± 26.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\nGPU, with shared memory:')\n",
    "%timeit fast_matmul_add_kernel[grid_dim, block_dim](a, b, c, out); cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about 2 orders of magnitude faster from gpu naive  implementation,f for more large matrix we will see that it will improves significantly. \n",
    "Now we can benchmark the performance.\n",
    "A timer function that takes in the function to be timed and its arguments. It then defines an equivalent (lambda) function with no arguments and times it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for the basic size 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU matmul add:\n",
      "788.40855 ms average time per run (mean of 7 runs, 1 loops each)\n",
      "\n",
      "GPU, naive implementation:\n",
      "255.57033 µs average time per run (mean of 7 runs, 10 loops each)\n",
      "\n",
      "GPU, with shared memory:\n",
      "232.20004 µs average time per run (mean of 7 runs, 10 loops each)\n",
      "\n",
      "numpy matmul add:\n",
      "68.54478 µs average time per run (mean of 7 runs, 10 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.to_device(c)\n",
    "d_out = cuda.to_device(np.zeros((N, N), dtype=np.float32))\n",
    "tmp_out = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "numpy_func = lambda: (np.matmul(a, b, out=tmp_out) + c)   \n",
    "cpu_func = lambda: cpu_matmul_add(a, b, c, cpu_out)\n",
    "gpu_naive = lambda: matmul_add_kernel[grid_dim, block_dim](d_a, d_b, d_c, d_out); cuda.synchronize()\n",
    "gpu_fast = lambda: fast_matmul_add_kernel[grid_dim, block_dim](d_a, d_b, d_c, d_out); cuda.synchronize()\n",
    "\n",
    "default_config = (7, 10, 'µs')\n",
    "cpu_config = (7, 1, 'ms')\n",
    "\n",
    "\n",
    "functions_dict = {'NUMPY' : (numpy_func, 'numpy matmul add', *default_config),\n",
    "                 'CPU' : (cpu_func, 'CPU matmul add', *cpu_config),\n",
    "                 'GPU_NAIVE' : (gpu_naive, 'GPU, naive implementation',  *default_config),\n",
    "                 'GPU_FAST' : (gpu_fast, 'GPU, with shared memory',  *default_config),\n",
    "                 }\n",
    "\n",
    "time_measurement(*functions_dict['CPU'])\n",
    "time_measurement(*functions_dict['GPU_NAIVE'])\n",
    "time_measurement(*functions_dict['GPU_FAST'])\n",
    "time_measurement(*functions_dict['NUMPY'])\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments for matrix of sizes: `32x32` ,  `128x128` ,  `512x512` , `1024x1024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "\n",
    "N_choices = [32, 128, 512, 1024]\n",
    "\n",
    "def run_experiment(N):\n",
    "    \n",
    "    print('\\n' + '=' * 75)\n",
    "    print(f'=========== [ matrix multiplication of {N:^5d} x {N:^5d} elements ] ===========')\n",
    "    print('=' * 75)\n",
    "    blocksize = cuda.get_current_device().WARP_SIZE\n",
    "    gridsize = (N + blocksize-1)//blocksize\n",
    "\n",
    "    block_dim = (blocksize, blocksize)\n",
    "    grid_dim = (gridsize, gridsize)\n",
    "    \n",
    "    print(f'block_dim={block_dim}, grid_dim={grid_dim} , total_threads={(blocksize**2) * (gridsize**2)}')\n",
    "\n",
    "    tmp_out = np.zeros((N, N), dtype=np.float32)\n",
    "    # Input data \n",
    "    a = np.random.rand(N, N) \n",
    "    b = np.random.rand(N, N) \n",
    "    c = np.random.rand(N, N) \n",
    "    cpu_out = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "    d_a = cuda.to_device(a)\n",
    "    d_b = cuda.to_device(b)\n",
    "    d_c = cuda.to_device(c)\n",
    "    d_out = cuda.to_device(np.zeros((N, N), dtype=np.float32))\n",
    "\n",
    "    print('\\nCPU matmul add:')\n",
    "    cpu_time = %timeit -o -r 1 -n 1 pass; cpu_matmul_add(a, b, c, cpu_out)\n",
    "    print_time(cpu_time)\n",
    "    \n",
    "\n",
    "    print('\\nnumpy matmul add:')\n",
    "    numpy_time = %timeit -o -r 5 -n 100  pass; (np.matmul(a, b, out=tmp_out) + c)\n",
    "    print_time(numpy_time)\n",
    "    \n",
    "    \n",
    "    print('\\nGPU, naive implementation:')\n",
    "    cuda_naive_time =  %timeit -o -r 5 -n 100 pass; matmul_add_kernel[grid_dim, block_dim](d_a, d_b, d_c, d_out); cuda.synchronize()\n",
    "    print_time(cuda_naive_time)\n",
    "\n",
    "    print('\\nGPU, with shared memory:')\n",
    "    cuda_fast_time =  %timeit -o -r 5 -n 100 pass; fast_matmul_add_kernel[grid_dim, block_dim](d_a, d_b, d_c, d_out); cuda.synchronize()\n",
    "    print_time(cuda_fast_time)\n",
    "    \n",
    "    return cpu_time, numpy_time, cuda_naive_time, cuda_fast_time \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This step might take a while, we used save_checkpoint strategy, the final checkpoints file will be loaded instead of running training.\n",
    "### if you want to run experiment, change the `force_run` below to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "=========== [ matrix multiplication of  32   x  32   elements ] ===========\n",
      "===========================================================================\n",
      "\n",
      "CPU matmul add:\n",
      "\n",
      "        Average time (ms) 28.1\n",
      "           Best time (ms) 28.1\n",
      "                 Std (ns) 0.0\n",
      "\n",
      "numpy matmul add:\n",
      "\n",
      "        Average time (µs) 16.5\n",
      "           Best time (µs) 13.1\n",
      "                 Std (µs) 3.1\n",
      "\n",
      "GPU, naive implementation:\n",
      "\n",
      "        Average time (µs) 340.4\n",
      "           Best time (µs) 325.2\n",
      "                 Std (µs) 11.1\n",
      "\n",
      "GPU, with shared memory:\n",
      "\n",
      "        Average time (µs) 299.1\n",
      "           Best time (µs) 296.2\n",
      "                 Std (µs) 5.2\n",
      "\n",
      "===========================================================================\n",
      "=========== [ matrix multiplication of  128  x  128  elements ] ===========\n",
      "===========================================================================\n",
      "\n",
      "CPU matmul add:\n",
      "\n",
      "        Average time (ms) 984.1\n",
      "           Best time (ms) 984.1\n",
      "                 Std (ns) 0.0\n",
      "\n",
      "numpy matmul add:\n",
      "\n",
      "        Average time (µs) 83.3\n",
      "           Best time (µs) 82.0\n",
      "                 Std (µs) 2.3\n",
      "\n",
      "GPU, naive implementation:\n",
      "\n",
      "        Average time (µs) 455.1\n",
      "           Best time (µs) 407.5\n",
      "                 Std (µs) 24.9\n",
      "\n",
      "GPU, with shared memory:\n",
      "\n",
      "        Average time (µs) 245.4\n",
      "           Best time (µs) 244.1\n",
      "                 Std (µs) 2.2\n",
      "\n",
      "===========================================================================\n",
      "=========== [ matrix multiplication of  512  x  512  elements ] ===========\n",
      "===========================================================================\n",
      "\n",
      "CPU matmul add:\n",
      "\n",
      "        Average time (s) 60.0\n",
      "           Best time (s) 60.0\n",
      "                 Std (ns) 0.0\n",
      "\n",
      "numpy matmul add:\n",
      "\n",
      "        Average time (ms) 3.5\n",
      "           Best time (ms) 3.5\n",
      "                 Std (µs) 11.7\n",
      "\n",
      "GPU, naive implementation:\n",
      "\n",
      "        Average time (ms) 5.5\n",
      "           Best time (ms) 5.2\n",
      "                 Std (µs) 431.4\n",
      "\n",
      "GPU, with shared memory:\n",
      "\n",
      "        Average time (ms) 2.7\n",
      "           Best time (ms) 2.7\n",
      "                 Std (µs) 1.5\n",
      "\n",
      "===========================================================================\n",
      "=========== [ matrix multiplication of 1024  x 1024  elements ] ===========\n",
      "===========================================================================\n",
      "\n",
      "CPU matmul add:\n",
      "\n",
      "        Average time (s) 465.2\n",
      "           Best time (s) 465.2\n",
      "                 Std (ns) 0.0\n",
      "\n",
      "numpy matmul add:\n",
      "\n",
      "        Average time (ms) 24.1\n",
      "           Best time (ms) 24.1\n",
      "                 Std (µs) 26.9\n",
      "\n",
      "GPU, naive implementation:\n",
      "\n",
      "        Average time (ms) 40.9\n",
      "           Best time (ms) 40.4\n",
      "                 Std (µs) 297.1\n",
      "\n",
      "GPU, with shared memory:\n",
      "\n",
      "        Average time (ms) 21.0\n",
      "           Best time (ms) 21.0\n",
      "                 Std (µs) 27.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import utils \n",
    "\n",
    "force_run = False\n",
    "results_file_path = os.path.join('exp.results.out')\n",
    "\n",
    "cpu_times, numpy_times, cuda_naive_times, cuda_fast_times = [], [], [], [] \n",
    "\n",
    "\n",
    "if not force_run and os.path.isfile(results_file_path):\n",
    "\n",
    "    with open(results_file_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "        cpu_times = results['CPU']\n",
    "        numpy_times = results['NUMPY']\n",
    "        cuda_naive_times = results['GPU_NAIVE']\n",
    "        cuda_fast_times = results['GPU_FAST']\n",
    "        \n",
    "    for i, N in enumerate(N_choices):\n",
    "        print('\\n' + '=' * 75)\n",
    "        print(f'=========== [ matrix multiplication of {N:^5d} x {N:^5d} elements ] ===========')\n",
    "        print('=' * 75)\n",
    "        \n",
    "        print('\\nCPU matmul add:')\n",
    "        print_time_from_file(cpu_times, i)\n",
    "\n",
    "        print('\\nnumpy matmul add:')\n",
    "        print_time_from_file(numpy_times, i)\n",
    "\n",
    "\n",
    "        print('\\nGPU, naive implementation:')\n",
    "        print_time_from_file(cuda_naive_times, i)\n",
    "\n",
    "        print('\\nGPU, with shared memory:')\n",
    "        print_time_from_file(cuda_fast_times, i)\n",
    "\n",
    "\n",
    "else: \n",
    "    for N in N_choices:\n",
    "        cpu_time, numpy_time, cuda_naive_time, cuda_fast_time = run_experiment(N)\n",
    "        cpu_times.append(cpu_time)\n",
    "        numpy_times.append(numpy_time)\n",
    "        cuda_naive_times.append(cuda_naive_time)\n",
    "        cuda_fast_times.append(cuda_fast_time)\n",
    "\n",
    "    print('\\nCPU matmul add:')\n",
    "    print_time_from_file(cpu_times, i)\n",
    "\n",
    "    print('\\nnumpy matmul add:')\n",
    "    print_time_from_file(numpy_times, i)\n",
    "\n",
    "\n",
    "    print('\\nGPU, naive implementation:')\n",
    "    print_time_from_file(cuda_naive_times, i)\n",
    "\n",
    "    print('\\nGPU, with shared memory:')\n",
    "    print_time_from_file(cuda_fast_times, i)    \n",
    "\n",
    "    results_dict = {'CPU' : [time_result_to_dict(t) for t in cpu_times],\n",
    "                    'NUMPY' : [time_result_to_dict(t) for t in numpy_times],\n",
    "                    'GPU_NAIVE' : [time_result_to_dict(t) for t in cuda_naive_times],\n",
    "                    'GPU_FAST' : [time_result_to_dict(t) for t in cuda_fast_times],\n",
    "                     }\n",
    "    \n",
    "    with open(results_file_path , 'w') as f:\n",
    "        json.dump(results_dict, f)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_79886832_af8a_11eb_ae71_ac1f6b89b006 tr:hover {\n",
       "          background-color: #ffff99;\n",
       "    }    #T_79886832_af8a_11eb_ae71_ac1f6b89b006  {\n",
       "          width: 1000px;\n",
       "          font-size: 16pt;\n",
       "          text-align: center;\n",
       "    }</style><table id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >CPU</th>        <th class=\"col_heading level0 col1\" >numpy</th>        <th class=\"col_heading level0 col2\" >GPU, naive</th>        <th class=\"col_heading level0 col3\" >GPU, fast</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006level0_row0\" class=\"row_heading level0 row0\" > 32   x  32  </th>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row0_col0\" class=\"data row0 col0\" >28.1 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row0_col1\" class=\"data row0 col1\" >16.5 (µs)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row0_col2\" class=\"data row0 col2\" >340.4 (µs)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row0_col3\" class=\"data row0 col3\" >299.1 (µs)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006level0_row1\" class=\"row_heading level0 row1\" > 128  x  128 </th>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row1_col0\" class=\"data row1 col0\" >984.1 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row1_col1\" class=\"data row1 col1\" >83.3 (µs)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row1_col2\" class=\"data row1 col2\" >455.1 (µs)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row1_col3\" class=\"data row1 col3\" >245.4 (µs)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006level0_row2\" class=\"row_heading level0 row2\" > 512  x  512 </th>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row2_col0\" class=\"data row2 col0\" >60.0 (s)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row2_col1\" class=\"data row2 col1\" >3.5 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row2_col2\" class=\"data row2 col2\" >5.5 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row2_col3\" class=\"data row2 col3\" >2.7 (ms)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006level0_row3\" class=\"row_heading level0 row3\" >1024  x 1024 </th>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row3_col0\" class=\"data row3 col0\" >465.2 (s)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row3_col1\" class=\"data row3 col1\" >24.1 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row3_col2\" class=\"data row3 col2\" >40.9 (ms)</td>\n",
       "                        <td id=\"T_79886832_af8a_11eb_ae71_ac1f6b89b006row3_col3\" class=\"data row3 col3\" >21.0 (ms)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff96077f640>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils \n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "df = get_summary_table(N_choices, cpu_times, numpy_times, cuda_naive_times, cuda_fast_times)\n",
    "\n",
    "def hover(hover_color=\"#ffff99\"):\n",
    "    return dict(selector=\"tr:hover\", props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "\n",
    "styles = [hover(), dict(props=[('width', '1000px'), (\"font-size\", \"16pt\"),(\"text-align\", \"center\")])]\n",
    "html = (df.style.set_table_styles(styles))\n",
    "html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "plt_results(N_choices, cpu_times, numpy_times, cuda_naive_times, cuda_fast_times, to_scale = 'µs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUDA provides a very powerful framework for easily writing highly scalable multithreaded code.\n",
    "- Once we have the right mental model about how it works, we can leverage the power of GPUs for performing arbitrary computation.\n",
    "- Using `numba`, we can do this directly in Python, and even iterate implementing our GPU code interactively within a jupyter notebook.\n",
    "- As a bonus, we learned how to accelerate any numerical python function with `numba`, and squeeze out extra performance gains even without a GPU.\n",
    "\n",
    "- As we can see, performing the same operation on a GPU gives us a speed-up of 70 times as on CPU.\n",
    "  This was still a small computation. For large scale computations, GPUs give us speed-ups of a few orders of magnitude.\n",
    "\n",
    "- For large scale computations, GPUs give us speed-ups even better than `numpy` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
